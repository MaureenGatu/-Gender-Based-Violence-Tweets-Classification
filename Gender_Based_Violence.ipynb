{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Gender Based Violence.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JwtiVzkyvkgS",
        "WznXBjF_vo42",
        "jUG4k2G_vwJ4",
        "a7RI-Ujav73t",
        "A6SzHJriwD0M",
        "5GF_YRBExQcZ",
        "qdLLn3UawT2I",
        "_18qKo05xr3y",
        "zcF_b6QK_rPv"
      ],
      "authorship_tag": "ABX9TyNmx1VKsGQziJj6XrInuftG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaureenGatu/-Gender-Based-Violence-Tweets-Classification/blob/main/Gender_Based_Violence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwtiVzkyvkgS"
      },
      "source": [
        "##Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsn5-m8P0Rz_",
        "outputId": "3b57d8a5-8cbf-42f9-e0f7-96b809b7617b"
      },
      "source": [
        "! python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |██████▏                         | 2.3 MB 5.1 MB/s eta 0:00:02\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "\u001b[?25hTraceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 1653, in _wait\n",
            "    (pid, sts) = self._try_wait(0)\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 1611, in _try_wait\n",
            "    (pid, sts) = os.waitpid(self.pid, wait_flags)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/__main__.py\", line 33, in <module>\n",
            "    plac.call(commands[command], sys.argv[1:])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/plac_core.py\", line 367, in call\n",
            "    cmd, result = parser.consume(arglist)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/plac_core.py\", line 232, in consume\n",
            "    return cmd, self.func(*(args + varargs + extraopts), **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/cli/download.py\", line 48, in download\n",
            "    dl = download_model(dl_tpl.format(m=model_name, v=version), pip_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/cli/download.py\", line 135, in download_model\n",
            "    return subprocess.call(cmd, env=os.environ.copy())\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 341, in call\n",
            "    return p.wait(timeout=timeout)\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 1019, in wait\n",
            "    return self._wait(timeout=timeout)\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 1658, in _wait\n",
            "    self._handle_exitstatus(sts)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcHGzuPg0i5Y",
        "outputId": "9e2b7580-9d10-481d-a774-dbba1f705690"
      },
      "source": [
        "! pip install sparknlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sparknlp\n",
            "  Downloading sparknlp-1.0.0-py3-none-any.whl (1.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sparknlp) (1.19.5)\n",
            "Collecting spark-nlp\n",
            "  Downloading spark_nlp-3.2.1-py2.py3-none-any.whl (116 kB)\n",
            "\u001b[K     |████████████████████████████████| 116 kB 5.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: spark-nlp, sparknlp\n",
            "Successfully installed spark-nlp-3.2.1 sparknlp-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "garSUcwX4KaR",
        "outputId": "ae569964-8f77-4f45-f353-55d172c1fc81"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#for text pre-processing\n",
        "import re, string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "#for model-building\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "# bag of words\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#for word embedding\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "import spacy\n",
        "#import sparknlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WznXBjF_vo42"
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "IAN92Orp4cqe",
        "outputId": "4d82bd88-c0ce-41e3-b922-fdc12182a403"
      },
      "source": [
        "#uploading the data\n",
        "\n",
        "df_train= pd.read_csv('/content/Train.csv')\n",
        "df_test=pd.read_csv('/content/Test.csv')\n",
        "df_train.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet_ID</th>\n",
              "      <th>tweet</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_0022DWKP</td>\n",
              "      <td>Had a dream i got raped last night. By a guy i...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_00395QYM</td>\n",
              "      <td>he thought the word raped means sex and told m...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_003EOSSF</td>\n",
              "      <td>She NOT TALKING TO ME I WAS RAPED BY 2 MEN 1 M...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_004BBHOD</td>\n",
              "      <td>I was sexually abused for 3 years at age 4 to ...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_004F7516</td>\n",
              "      <td>Chessy Prout can do better by telling the trut...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ID_0052TYKI</td>\n",
              "      <td>Yes men rape women. But women also rape men, y...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ID_0058QG76</td>\n",
              "      <td>My Husband Beats Me Frequently, Wife Tells Cou...</td>\n",
              "      <td>Physical_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ID_005VM1DJ</td>\n",
              "      <td>Pretty sure he raped a 16yr old girl with 2 fr...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ID_0060BW8R</td>\n",
              "      <td>TW sorry to hear that  and yeah he recently th...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ID_007FAIEI</td>\n",
              "      <td>\"I understand that... My father was abusive as...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ID_00A89HJ5</td>\n",
              "      <td>but i would be here all night if i tried to te...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ID_00APGSBM</td>\n",
              "      <td>BABY! Soon, all the notes in case ya'll suck y...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>ID_00AWI88Y</td>\n",
              "      <td>He orally raped me. This is not hearsay. Multi...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ID_00B6KO4G</td>\n",
              "      <td>When i was off both jobs drive to another coun...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ID_00BXFFCR</td>\n",
              "      <td>This is such a ridiculous thing to say. A viol...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Tweet_ID  ...               type\n",
              "0   ID_0022DWKP  ...    sexual_violence\n",
              "1   ID_00395QYM  ...    sexual_violence\n",
              "2   ID_003EOSSF  ...    sexual_violence\n",
              "3   ID_004BBHOD  ...    sexual_violence\n",
              "4   ID_004F7516  ...    sexual_violence\n",
              "5   ID_0052TYKI  ...    sexual_violence\n",
              "6   ID_0058QG76  ...  Physical_violence\n",
              "7   ID_005VM1DJ  ...    sexual_violence\n",
              "8   ID_0060BW8R  ...    sexual_violence\n",
              "9   ID_007FAIEI  ...    sexual_violence\n",
              "10  ID_00A89HJ5  ...    sexual_violence\n",
              "11  ID_00APGSBM  ...    sexual_violence\n",
              "12  ID_00AWI88Y  ...    sexual_violence\n",
              "13  ID_00B6KO4G  ...    sexual_violence\n",
              "14  ID_00BXFFCR  ...    sexual_violence\n",
              "\n",
              "[15 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKSMH6nT40DM",
        "outputId": "5304abeb-4837-47c9-e543-792eeb5136b8"
      },
      "source": [
        "# view the prediction categories\n",
        "import seaborn as sns\n",
        "x=df_train['type'].value_counts()\n",
        "print(x)\n",
        "sns.barplot(x.index,x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sexual_violence                 32648\n",
            "Physical_violence                5946\n",
            "emotional_violence                651\n",
            "economic_violence                 217\n",
            "Harmful_Traditional_practice      188\n",
            "Name: type, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f43a6a1e410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUG4k2G_vwJ4"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hj79l-KQa3W"
      },
      "source": [
        "# df_train['type'] = df_train['type'].map({'sexual_violence': 0, 'Physical_violence': 1, 'emotional_violence': 2,\n",
        "#                              'Harmful_Traditional_practice': 3, 'economic_violence': 4})\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "df_train['type'] = le.fit_transform(df_train['type'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tOLnrHp87G8",
        "outputId": "f6eb9df5-568f-439a-975d-1465c96574ef"
      },
      "source": [
        "#1. WORD-COUNT\n",
        "df_train['word_count'] = df_train['tweet'].apply(lambda x: len(str(x).split()))\n",
        "print(df_train[df_train['type']==0]['word_count'].mean()) #Abuse tweets\n",
        "print(df_train[df_train['type']==1]['word_count'].mean()) #Non-Disaster tweets\n",
        "print(df_train[df_train['type']==2]['word_count'].mean()) \n",
        "print(df_train[df_train['type']==3]['word_count'].mean()) \n",
        "print(df_train[df_train['type']==4]['word_count'].mean()) \n",
        "print('***'*30)\n",
        "#Disaster tweets are more wordy than the non-disaster tweets\n",
        "\n",
        "#2. CHARACTER-COUNT\n",
        "df_train['char_count'] = df_train['tweet'].apply(lambda x: len(str(x)))\n",
        "print(df_train[df_train['type']==0]['char_count'].mean()) #Disaster tweets\n",
        "print(df_train[df_train['type']==1]['char_count'].mean())\n",
        "print(df_train[df_train['type']==2]['char_count'].mean())\n",
        "print(df_train[df_train['type']==3]['char_count'].mean())\n",
        "print(df_train[df_train['type']==4]['char_count'].mean())\n",
        "print('***'*30) #Non-Disaster tweets\n",
        "#Disaster tweets are longer than the non-disaster tweets\n",
        "\n",
        "#3. UNIQUE WORD-COUNT\n",
        "df_train['unique_word_count'] = df_train['tweet'].apply(lambda x: len(set(str(x).split())))\n",
        "print(df_train[df_train['type']==0]['unique_word_count'].mean()) #Disaster tweets\n",
        "print(df_train[df_train['type']==1]['unique_word_count'].mean()) #Non-Disaster tweets\n",
        "print(df_train[df_train['type']==2]['unique_word_count'].mean())\n",
        "print(df_train[df_train['type']==3]['unique_word_count'].mean())\n",
        "print(df_train[df_train['type']==4]['unique_word_count'].mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33.920212765957444\n",
            "23.301883619239824\n",
            "40.534562211981566\n",
            "38.48233486943165\n",
            "41.74981622151434\n",
            "******************************************************************************************\n",
            "191.7659574468085\n",
            "122.67574840228725\n",
            "205.38248847926266\n",
            "202.65284178187403\n",
            "213.30792085273217\n",
            "******************************************************************************************\n",
            "30.22340425531915\n",
            "21.474100235452404\n",
            "34.31336405529954\n",
            "33.78033794162826\n",
            "36.008208772359716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yx3kYMZi5Bqj",
        "outputId": "8e127e3f-5539-424e-8907-c679d23384bb"
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tweet_ID             0\n",
              "tweet                0\n",
              "type                 0\n",
              "word_count           0\n",
              "char_count           0\n",
              "unique_word_count    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TkmhfJl_2oQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "995fff34-c3ab-4dbb-9633-e5249484cbba"
      },
      "source": [
        "# Converting all characters in the message to lower case\n",
        "# \n",
        "df_train['clean_text'] = df_train['tweet']\n",
        "df_train['clean_text'] = df_train['clean_text'].map(lambda x: x.lower())\n",
        "\n",
        "# Removing any punctuation\n",
        "# \n",
        "df_train['clean_text'] = df_train['clean_text'].str.replace('[^\\w\\s_]', '')\n",
        "\n",
        "# Removing numbers from strings of speciafied \n",
        "# Column, here 'tweet'\n",
        "df_train['clean_text'] = df_train['clean_text'].str.replace('\\d+', '')\n",
        "\n",
        "# nlp = spacy.load('en')\n",
        "\n",
        "# df_train['clean_text2']  = df_train['clean_text'].apply(lambda x: nlp(x))\n",
        "\n",
        "df_train.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet_ID</th>\n",
              "      <th>tweet</th>\n",
              "      <th>type</th>\n",
              "      <th>word_count</th>\n",
              "      <th>char_count</th>\n",
              "      <th>unique_word_count</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13062</th>\n",
              "      <td>ID_BU2T4MLV</td>\n",
              "      <td>SHOCKING: Wife reveals at Court- 'My Husband B...</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>104</td>\n",
              "      <td>18</td>\n",
              "      <td>shocking wife reveals at court my husband beat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35988</th>\n",
              "      <td>ID_WSGOOLDF</td>\n",
              "      <td>A girl got coerced and raped at 14...but no, \"...</td>\n",
              "      <td>4</td>\n",
              "      <td>45</td>\n",
              "      <td>221</td>\n",
              "      <td>39</td>\n",
              "      <td>a girl got coerced and raped at but no me i wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19083</th>\n",
              "      <td>ID_HE0SMU3J</td>\n",
              "      <td>Racist. He calls covid the kung-flu and china ...</td>\n",
              "      <td>4</td>\n",
              "      <td>31</td>\n",
              "      <td>151</td>\n",
              "      <td>27</td>\n",
              "      <td>racist he calls covid the kungflu and china vi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34587</th>\n",
              "      <td>ID_VI61FRM3</td>\n",
              "      <td>my dad just said that if i got raped he’d want...</td>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "      <td>73</td>\n",
              "      <td>17</td>\n",
              "      <td>my dad just said that if i got raped hed want ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1759</th>\n",
              "      <td>ID_1KHJTO56</td>\n",
              "      <td>I am begging you for help. Is it possible to i...</td>\n",
              "      <td>4</td>\n",
              "      <td>42</td>\n",
              "      <td>189</td>\n",
              "      <td>36</td>\n",
              "      <td>i am begging you for help is it possible to im...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Tweet_ID  ...                                         clean_text\n",
              "13062  ID_BU2T4MLV  ...  shocking wife reveals at court my husband beat...\n",
              "35988  ID_WSGOOLDF  ...  a girl got coerced and raped at but no me i wa...\n",
              "19083  ID_HE0SMU3J  ...  racist he calls covid the kungflu and china vi...\n",
              "34587  ID_VI61FRM3  ...  my dad just said that if i got raped hed want ...\n",
              "1759   ID_1KHJTO56  ...  i am begging you for help is it possible to im...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "JLxiNnqIOhY3",
        "outputId": "f53ab236-6cc8-4143-8e8c-778cd73b9dee"
      },
      "source": [
        "df_train['clean_text2']  = df_train['clean_text']\n",
        "df_train.drop(['clean_text2'], axis=1, inplace= True)\n",
        "df_train.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet_ID</th>\n",
              "      <th>tweet</th>\n",
              "      <th>type</th>\n",
              "      <th>word_count</th>\n",
              "      <th>char_count</th>\n",
              "      <th>unique_word_count</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34296</th>\n",
              "      <td>ID_V8SSQ7RT</td>\n",
              "      <td>I lived there ... i took those pictures of Lob...</td>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "      <td>193</td>\n",
              "      <td>37</td>\n",
              "      <td>i lived there  i took those pictures of lobo a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15001</th>\n",
              "      <td>ID_DMURNVDA</td>\n",
              "      <td>Jorge wrote his name down on this and put \"mil...</td>\n",
              "      <td>4</td>\n",
              "      <td>53</td>\n",
              "      <td>286</td>\n",
              "      <td>47</td>\n",
              "      <td>jorge wrote his name down on this and put mill...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5839</th>\n",
              "      <td>ID_59IDSCC7</td>\n",
              "      <td>How bad has it gotten in our land?  This doesn...</td>\n",
              "      <td>4</td>\n",
              "      <td>21</td>\n",
              "      <td>106</td>\n",
              "      <td>21</td>\n",
              "      <td>how bad has it gotten in our land  this doesnt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2936</th>\n",
              "      <td>ID_2NHE1D5E</td>\n",
              "      <td>Anyway, my rapists name is Joshua Deguzman. He...</td>\n",
              "      <td>4</td>\n",
              "      <td>60</td>\n",
              "      <td>279</td>\n",
              "      <td>43</td>\n",
              "      <td>anyway my rapists name is joshua deguzman he u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5725</th>\n",
              "      <td>ID_55BNU2KD</td>\n",
              "      <td>Yea men have gone through it but I’d bet y’all...</td>\n",
              "      <td>4</td>\n",
              "      <td>59</td>\n",
              "      <td>284</td>\n",
              "      <td>50</td>\n",
              "      <td>yea men have gone through it but id bet yall a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Tweet_ID  ...                                         clean_text\n",
              "34296  ID_V8SSQ7RT  ...  i lived there  i took those pictures of lobo a...\n",
              "15001  ID_DMURNVDA  ...  jorge wrote his name down on this and put mill...\n",
              "5839   ID_59IDSCC7  ...  how bad has it gotten in our land  this doesnt...\n",
              "2936   ID_2NHE1D5E  ...  anyway my rapists name is joshua deguzman he u...\n",
              "5725   ID_55BNU2KD  ...  yea men have gone through it but id bet yall a...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHYwhgui5GfH"
      },
      "source": [
        "# # PLOTTING WORD-COUNT\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,4))\n",
        "# train_words=df_train[df_train['type']==1]['tweet']\n",
        "# ax1.hist(train_words,color='red')\n",
        "# ax1.set_title('Disaster tweets')\n",
        "# train_words=df_train[df_train['type']==0]['tweet']\n",
        "# ax2.hist(train_words,color='green')\n",
        "# ax2.set_title('Non-disaster tweets')\n",
        "# fig.suptitle('Words per tweet')\n",
        "# plt.show()\n",
        "\n",
        "from nltk.util import ngrams\n",
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyyKTEYO5j9y"
      },
      "source": [
        "#convert to lowercase, strip and remove punctuations\n",
        "def preprocess(text):\n",
        "    text = text.lower() \n",
        "    text=text.strip()  \n",
        "    text=re.compile('<.*?>').sub('', text) \n",
        "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
        "    text = re.sub('\\s+', ' ', text)  \n",
        "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
        "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
        "    text = re.sub(r'\\d',' ',text) \n",
        "    text = re.sub(r'\\s+',' ',text) \n",
        "    text = re.sub(\"@\\S+\", \"\", text)\n",
        "    re.sub(\"\\$\", \"\", text)\n",
        "    text = re.sub(\"https?:\\/\\/.*[\\r\\n]*\", \"\", text)\n",
        "    re.sub(\"#\", \"\", text)\n",
        "    return text\n",
        "\n",
        "\n",
        "#tokenizer, pos tagging and entity recognition\n",
        "\n",
        " \n",
        "# STOPWORD REMOVAL\n",
        "def stopword(string):\n",
        "    a= [i for i in string.split() if i not in stopwords.words('english')]\n",
        "    return ' '.join(a)\n",
        "#LEMMATIZATION\n",
        "# Initialize the lemmatizer\n",
        "wl = WordNetLemmatizer()\n",
        " \n",
        "# This is a helper function to map NTLK position tags\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "# Tokenize the sentence\n",
        "def lemmatizer(string):\n",
        "    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags\n",
        "    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n",
        "    return \" \".join(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpV6ZlG46C3H",
        "outputId": "bd4b41f2-bf7e-4ebf-84d6-c2f79c35415a"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrIaap775u15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "0dfe23d1-a68c-4ca7-9210-1e160c9748d2"
      },
      "source": [
        "def finalpreprocess(string):\n",
        "    return lemmatizer(stopword(preprocess(string)))\n",
        "df_train['clean_text'] = df_train['tweet'].apply(lambda x: finalpreprocess(x))\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet_ID</th>\n",
              "      <th>tweet</th>\n",
              "      <th>type</th>\n",
              "      <th>word_count</th>\n",
              "      <th>char_count</th>\n",
              "      <th>unique_word_count</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_0022DWKP</td>\n",
              "      <td>Had a dream i got raped last night. By a guy i...</td>\n",
              "      <td>4</td>\n",
              "      <td>45</td>\n",
              "      <td>203</td>\n",
              "      <td>40</td>\n",
              "      <td>dream get rap last night guy work actually guy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_00395QYM</td>\n",
              "      <td>he thought the word raped means sex and told m...</td>\n",
              "      <td>4</td>\n",
              "      <td>21</td>\n",
              "      <td>100</td>\n",
              "      <td>20</td>\n",
              "      <td>think word rap mean sex tell saw dog rap eacho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_003EOSSF</td>\n",
              "      <td>She NOT TALKING TO ME I WAS RAPED BY 2 MEN 1 M...</td>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>104</td>\n",
              "      <td>23</td>\n",
              "      <td>talk rap men molest jail nother charge say word</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_004BBHOD</td>\n",
              "      <td>I was sexually abused for 3 years at age 4 to ...</td>\n",
              "      <td>4</td>\n",
              "      <td>61</td>\n",
              "      <td>280</td>\n",
              "      <td>50</td>\n",
              "      <td>sexually abused year age one believe rap bros ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_004F7516</td>\n",
              "      <td>Chessy Prout can do better by telling the trut...</td>\n",
              "      <td>4</td>\n",
              "      <td>52</td>\n",
              "      <td>278</td>\n",
              "      <td>44</td>\n",
              "      <td>chessy prout good tell truth sell owen labrie ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Tweet_ID  ...                                         clean_text\n",
              "0  ID_0022DWKP  ...  dream get rap last night guy work actually guy...\n",
              "1  ID_00395QYM  ...  think word rap mean sex tell saw dog rap eacho...\n",
              "2  ID_003EOSSF  ...    talk rap men molest jail nother charge say word\n",
              "3  ID_004BBHOD  ...  sexually abused year age one believe rap bros ...\n",
              "4  ID_004F7516  ...  chessy prout good tell truth sell owen labrie ...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y_xvIwDNk1W"
      },
      "source": [
        "#preprocessing test data\n",
        "df_test['clean_text'] = df_test['tweet'].apply(lambda x: finalpreprocess(x)) #preprocess the data\n",
        "X_test=df_test['clean_text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFHRMQt-90TO",
        "outputId": "ab242ec5-ce55-4f41-a776-45a1548b44f0"
      },
      "source": [
        "\n",
        "# create Word2vec model\n",
        "#here words_f should be a list containing words from each document. say 1st row of the list is words from the 1st document/sentence\n",
        "#length of words_f is number of documents/sentences in your dataset\n",
        "df_train['clean_text_tok']=[nltk.word_tokenize(i) for i in df_train['clean_text']] #convert preprocessed sentence to tokenized sentence\n",
        "model = Word2Vec(df_train['clean_text_tok'],min_count=1)  #min_count=1 means word should be present at least across all documents,\n",
        "#if min_count=2 means if the word is present less than 2 times across all the documents then we shouldn't consider it\n",
        "\n",
        "\n",
        "w2v = dict(zip(model.wv.index2word, model.wv.syn0))  #combination of word and its vector\n",
        "\n",
        "#for converting sentence to vectors/numbers from word vectors result by Word2Vec\n",
        "class MeanEmbeddingVectorizer(object):\n",
        "    def __init__(self, word2vec):\n",
        "        self.word2vec = word2vec\n",
        "        # if a text is empty we should return a vector of zeros\n",
        "        # with the same dimensionality as all the other vectors\n",
        "        self.dim = len(next(iter(word2vec.values())))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([\n",
        "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
        "                    or [np.zeros(self.dim)], axis=0)\n",
        "            for words in X\n",
        "        ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7RI-Ujav73t"
      },
      "source": [
        "## Vectorizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCYPuBrX_JeH"
      },
      "source": [
        "#SPLITTING THE TRAINING DATASET INTO TRAINING AND VALIDATION\n",
        " \n",
        "# Input: \"reviewText\", \"rating\" and \"time\"\n",
        "# Target: \"log_votes\"\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(df_train[\"clean_text\"],\n",
        "                                                  df_train[\"type\"],\n",
        "                                                  test_size=0.05,\n",
        "                                                  shuffle=True,\n",
        "                                                  stratify =df_train[\"type\"] )\n",
        "X_train_tok= [nltk.sent_tokenize(i) for i in X_train]  #for word2vec\n",
        "X_val_tok= [nltk.sent_tokenize(i) for i in X_val]      #for word2vec\n",
        "\n",
        "#TF-IDF\n",
        "# Convert x_train to vector since model can only run on numbers and not words- Fit and transform\n",
        "tfidf_vectorizer = TfidfVectorizer(use_idf=True, )\n",
        "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train) #tfidf runs on non-tokenized sentences unlike word2vec\n",
        "# Only transform x_test (not fit and transform)\n",
        "X_val_vectors_tfidf = tfidf_vectorizer.transform(X_val) #Don't fit() your TfidfVectorizer to your test data: it will \n",
        "#change the word-indexes & weights to match test data. Rather, fit on the training data, then use the same train-data-\n",
        "#fit model on the test data, to reflect the fact you're analyzing the test data only based on what was learned without \n",
        "#it, and the have compatible\n",
        "\n",
        "\n",
        "#Word2vec\n",
        "# Fit and transform\n",
        "modelw = MeanEmbeddingVectorizer(w2v)\n",
        "X_train_vectors_w2v = modelw.transform(X_train_tok)\n",
        "X_val_vectors_w2v = modelw.transform(X_val_tok)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNAiacPQwAz5"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6SzHJriwD0M"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Vsn80naG9Lm"
      },
      "source": [
        "### base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-2QQuyzYMdX",
        "outputId": "47326b84-e6eb-47f1-c6c5-ce9a914a0cc7"
      },
      "source": [
        "lr_tfidf=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
        "lr_tfidf.fit(X_train_vectors_tfidf, y_train)  #model\n",
        "\n",
        "from pprint import pprint\n",
        "pprint(lr_tfidf.get_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method BaseEstimator.get_params of LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFj7adctqbPW",
        "outputId": "5a7af625-cdf3-4365-9718-cb2fc4fa0a7b"
      },
      "source": [
        "#FITTING THE CLASSIFICATION MODEL using Logistic Regression(tf-idf)\n",
        "\n",
        "lr_tfidf=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
        "lr_tfidf.fit(X_train_vectors_tfidf, y_train)  #model\n",
        "\n",
        "#Predict y value for test dataset\n",
        "y_predict = lr_tfidf.predict(X_val_vectors_tfidf)\n",
        "y_prob = lr_tfidf.predict_proba(X_val_vectors_tfidf)[:,1]\n",
        " \n",
        "\n",
        "print(classification_report(y_val,y_predict))\n",
        "print('Confusion Matrix:\\n',confusion_matrix(y_val, y_predict))\n",
        " \n",
        "baselog_accuracy = accuracy_score(y_val, y_predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89        10\n",
            "           1       0.99      1.00      0.99       332\n",
            "           2       0.86      0.75      0.80         8\n",
            "           3       1.00      1.00      1.00        43\n",
            "           4       1.00      1.00      1.00      1590\n",
            "\n",
            "    accuracy                           1.00      1983\n",
            "   macro avg       0.97      0.91      0.94      1983\n",
            "weighted avg       1.00      1.00      1.00      1983\n",
            "\n",
            "Confusion Matrix:\n",
            " [[   8    0    0    0    2]\n",
            " [   0  331    0    0    1]\n",
            " [   0    0    6    0    2]\n",
            " [   0    0    0   43    0]\n",
            " [   0    3    1    0 1586]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "17IOiaG2_UuX",
        "outputId": "4d03be87-1aac-4883-f9d6-7d1671e2a492"
      },
      "source": [
        "#FITTING THE CLASSIFICATION MODEL using Logistic Regression(tf-idf)\n",
        "\n",
        "lr_tfidf=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
        "lr_tfidf.fit(X_train_vectors_tfidf, y_train)  #model\n",
        "\n",
        "#Predict y value for test dataset\n",
        "y_predict = lr_tfidf.predict(X_val_vectors_tfidf)\n",
        "y_prob = lr_tfidf.predict_proba(X_val_vectors_tfidf)[:,1]\n",
        " \n",
        "\n",
        "print(classification_report(y_val,y_predict))\n",
        "print('Confusion Matrix:\\n',confusion_matrix(y_val, y_predict))\n",
        " \n",
        "baselog_accuracy = accuracy_score(y_val, y_predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95        10\n",
            "           1       0.98      0.99      0.98       277\n",
            "           2       0.92      0.92      0.92        13\n",
            "           3       1.00      0.90      0.95        30\n",
            "           4       0.99      1.00      1.00      1653\n",
            "\n",
            "    accuracy                           0.99      1983\n",
            "   macro avg       0.98      0.94      0.96      1983\n",
            "weighted avg       0.99      0.99      0.99      1983\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-80933fb959ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Confusion Matrix:\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mbaselog_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "SYRsNwnKH0QX",
        "outputId": "43e8a365-95c5-473d-9fa4-eadbb1d4bbac"
      },
      "source": [
        "\n",
        "#Testing it on new dataset with the best model\n",
        "#df_test=pd.read_csv('test.csv')  #reading the data\n",
        "\n",
        "#preprocessing\n",
        "#df_test['clean_text'] = df_test['tweet'].apply(lambda x: finalpreprocess(x)) #preprocess the data\n",
        "X_test=df_test['clean_text'] \n",
        "\n",
        "#text to vector\n",
        "X_vector=tfidf_vectorizer.transform(X_test) #converting X_test to vector\n",
        "y_predict = lr_tfidf.predict(X_vector)      #use the trained model on X_vector\n",
        "#y_prob = lr_tfidf.predict_proba(X_vector)[:,1]\n",
        "#df_test['predict_prob']= y_prob\n",
        "y_predict = le.inverse_transform(y_predict)\n",
        "df_test['type']= y_predict\n",
        "print(df_test.head())\n",
        "\n",
        ".drop([ 'tweet', 'clean_text',], axis = 1, inplace = True)\n",
        "attempt1.to_csv('Log_submission.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-7c71497f9e12>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    .drop([ 'tweet', 'clean_text',], axis = 1, inplace = True)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONPRJDiMJU40"
      },
      "source": [
        "attempt1 = df_test.copy(deep=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu1CdfxRJdo8"
      },
      "source": [
        "attempt1.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kSBY7tgJ8rf"
      },
      "source": [
        "attempt1.drop([ 'tweet', 'clean_text',], axis = 1, inplace = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_m7Dq9OKQDB"
      },
      "source": [
        "attempt1.to_csv('Log_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJnx59dYFpmn"
      },
      "source": [
        "### class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R83xszEBFsuV"
      },
      "source": [
        "# # Import the libraries\n",
        "# from sklearn.datasets import make_classification\n",
        "\n",
        "# from imblearn.over_sampling import SVMSMOTE\n",
        "# lr_tfidf = SVMSMOTE(random_state = 101)\n",
        "\n",
        "# # Choosing a sample\n",
        "# X_oversample_svm, y_oversample_svm = make_classification(n_samples=10000, n_features=2,\n",
        "#                                                          n_redundant=0, n_clusters_per_class=1,\n",
        "#                                                          weights=[0.99], flip_y=0, random_state=101)\n",
        "\n",
        "# # Perform Logistic Regression\n",
        "# X_oversample_svm, y_oversample_svm = lr_tfidf.fit_resample(X_train_vectors_tfidf, y_train)\n",
        "# classifier_svm = LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
        "# classifier_svm.fit(X_oversample_svm, y_oversample_svm)\n",
        "\n",
        "# #Predict y value for test dataset\n",
        "# y_predict = classifier_svm.predict(X_val_vectors_tfidf)\n",
        "# y_prob = classifier_svm.predict_proba(X_val_vectors_tfidf)[:,1]\n",
        " \n",
        "\n",
        "# print(classification_report(y_val, y_predict))\n",
        "# print('Confusion Matrix:',confusion_matrix(y_val, y_predict))\n",
        " \n",
        "\n",
        "# #print(classification_report(y_test, classifier_svm.predict(X_test)))\n",
        "# accuracy_score(y_val, y_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VW7FgXau6Jv",
        "outputId": "d162ec13-d049-4cc9-e159-caf6a456931c"
      },
      "source": [
        "# Import the libraries\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "from imblearn.over_sampling import SVMSMOTE\n",
        "lr_tfidf = SVMSMOTE(random_state = 101)\n",
        "\n",
        "# Choosing a sample\n",
        "X_oversample_svm, y_oversample_svm = make_classification(n_samples=10000, n_features=2,\n",
        "                                                         n_redundant=0, n_clusters_per_class=1,\n",
        "                                                         weights=[0.99], flip_y=0, random_state=101)\n",
        "\n",
        "# Perform Logistic Regression\n",
        "X_oversample_svm, y_oversample_svm = lr_tfidf.fit_resample(X_train_vectors_tfidf, y_train)\n",
        "classifier_svm = LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
        "classifier_svm.fit(X_oversample_svm, y_oversample_svm)\n",
        "\n",
        "#Predict y value for test dataset\n",
        "y_predict = classifier_svm.predict(X_val_vectors_tfidf)\n",
        "y_prob = classifier_svm.predict_proba(X_val_vectors_tfidf)[:,1]\n",
        " \n",
        "\n",
        "print(classification_report(y_val, y_predict))\n",
        "#print('Confusion Matrix:',confusion_matrix(y_val, y_predict))              #Model score zindi : 0.761446298673513\n",
        " \n",
        "\n",
        "#print(classification_report(y_test, classifier_svm.predict(X_test)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95         9\n",
            "           1       0.99      1.00      0.99       297\n",
            "           2       1.00      1.00      1.00        11\n",
            "           3       0.97      1.00      0.99        33\n",
            "           4       1.00      1.00      1.00      1633\n",
            "\n",
            "    accuracy                           1.00      1983\n",
            "   macro avg       0.97      1.00      0.98      1983\n",
            "weighted avg       1.00      1.00      1.00      1983\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kMR4WiZxU2m",
        "outputId": "391f777e-92a2-49e1-8207-f1fe3d96dc34"
      },
      "source": [
        "accuracy_score(y_val, y_predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9969742813918305"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t3-hRX-GhMm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28328e69-935e-4919-952d-c291c56d3c65"
      },
      "source": [
        "#text to vector\n",
        "X_vector=tfidf_vectorizer.transform(X_test) #converting X_test to vector\n",
        "y_predict_ps = classifier_svm.predict(X_vector)      #use the trained model on X_vector\n",
        "\n",
        "\n",
        "y_predict_ps = le.inverse_transform(y_predict_ps)\n",
        "\n",
        "df_test['type']= y_predict_ps\n",
        "dff = df_test.copy()\n",
        "\n",
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet_ID</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_0095QL4S</td>\n",
              "      <td>because he was my boyfriend, and if I said no,...</td>\n",
              "      <td>boyfriend say would get mad hat sex force sex ...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_00DREW5O</td>\n",
              "      <td>lol no, I'm telling you it's not legal. It's l...</td>\n",
              "      <td>lol tell legal literally crime conversation ra...</td>\n",
              "      <td>Harmful_Traditional_practice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_00E9F5X9</td>\n",
              "      <td>Somalia's semi-autonomous Puntland region has ...</td>\n",
              "      <td>somalia semi autonomous puntland region take f...</td>\n",
              "      <td>Harmful_Traditional_practice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_00G9OSKZ</td>\n",
              "      <td>University of Cape Coast students being robbed...</td>\n",
              "      <td>university cape coast student rob rap armed ro...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_00HU96U6</td>\n",
              "      <td>\"Somebody came up behind him and stabbed him i...</td>\n",
              "      <td>somebody come behind stab back really long bla...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15576</th>\n",
              "      <td>ID_ZZR1D21T</td>\n",
              "      <td>A Teesside charity has filed a “super complain...</td>\n",
              "      <td>teesside charity file super complaint allege s...</td>\n",
              "      <td>Harmful_Traditional_practice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15577</th>\n",
              "      <td>ID_ZZSQF54Y</td>\n",
              "      <td>he ... forced me to have sex with him.</td>\n",
              "      <td>force sex</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15578</th>\n",
              "      <td>ID_ZZTN5126</td>\n",
              "      <td>Female student of medical university raped at ...</td>\n",
              "      <td>female student medical university rap gunpoint...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15579</th>\n",
              "      <td>ID_ZZWS0XZZ</td>\n",
              "      <td>Bokamoso Mpembe (20 months) (Kidnapped and kil...</td>\n",
              "      <td>bokamoso mpembe month kidnap kill mother ex bo...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15580</th>\n",
              "      <td>ID_ZZZE5A5Q</td>\n",
              "      <td>Confession: Never Really Over reminds me of my...</td>\n",
              "      <td>confession never really remind ex absolutely s...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15581 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Tweet_ID  ...                          type\n",
              "0      ID_0095QL4S  ...               sexual_violence\n",
              "1      ID_00DREW5O  ...  Harmful_Traditional_practice\n",
              "2      ID_00E9F5X9  ...  Harmful_Traditional_practice\n",
              "3      ID_00G9OSKZ  ...               sexual_violence\n",
              "4      ID_00HU96U6  ...               sexual_violence\n",
              "...            ...  ...                           ...\n",
              "15576  ID_ZZR1D21T  ...  Harmful_Traditional_practice\n",
              "15577  ID_ZZSQF54Y  ...               sexual_violence\n",
              "15578  ID_ZZTN5126  ...               sexual_violence\n",
              "15579  ID_ZZWS0XZZ  ...               sexual_violence\n",
              "15580  ID_ZZZE5A5Q  ...               sexual_violence\n",
              "\n",
              "[15581 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgMDltRPxf6Y",
        "outputId": "846334ed-a17a-4831-9667-5fa4b8b44aa3"
      },
      "source": [
        "dff.drop([ 'tweet', 'clean_text'], axis = 1, inplace = True)\n",
        "dff.set_index('Tweet_ID', inplace=True)\n",
        "#df_test['type']= y_predict_ps\n",
        "dff"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tweet_ID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ID_0095QL4S</th>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID_00DREW5O</th>\n",
              "      <td>Harmful_Traditional_practice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID_00E9F5X9</th>\n",
              "      <td>Harmful_Traditional_practice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID_00G9OSKZ</th>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID_00HU96U6</th>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID_ZZR1D21T</th>\n",
              "      <td>Harmful_Traditional_practice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID_ZZSQF54Y</th>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID_ZZTN5126</th>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID_ZZWS0XZZ</th>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID_ZZZE5A5Q</th>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15581 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     type\n",
              "Tweet_ID                                 \n",
              "ID_0095QL4S               sexual_violence\n",
              "ID_00DREW5O  Harmful_Traditional_practice\n",
              "ID_00E9F5X9  Harmful_Traditional_practice\n",
              "ID_00G9OSKZ               sexual_violence\n",
              "ID_00HU96U6               sexual_violence\n",
              "...                                   ...\n",
              "ID_ZZR1D21T  Harmful_Traditional_practice\n",
              "ID_ZZSQF54Y               sexual_violence\n",
              "ID_ZZTN5126               sexual_violence\n",
              "ID_ZZWS0XZZ               sexual_violence\n",
              "ID_ZZZE5A5Q               sexual_violence\n",
              "\n",
              "[15581 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5BpQXAtxxal"
      },
      "source": [
        "dff.to_csv('Log_strfd_PS2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GF_YRBExQcZ"
      },
      "source": [
        "### MultiNomialNB Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPKS0njcCeMJ",
        "outputId": "304c2abf-a90c-40d7-bd5e-28dc6013ce78"
      },
      "source": [
        "#FITTING THE CLASSIFICATION MODEL using Naive Bayes(tf-idf)\n",
        "#It's a probabilistic classifier that makes use of Bayes' Theorem, a rule that uses probability to make predictions based on prior knowledge of conditions that might be related. This algorithm is the most suitable for such large dataset as it considers each feature independently, calculates the probability of each category, and then predicts the category with the highest probability.\n",
        "\n",
        "nb_tfidf = MultinomialNB()\n",
        "nb_tfidf.fit(X_train_vectors_tfidf, y_train)  #model\n",
        "\n",
        "#Predict y value for test dataset\n",
        "y_predict = nb_tfidf.predict(X_val_vectors_tfidf)\n",
        "y_prob = nb_tfidf.predict_proba(X_val_vectors_tfidf)[:,1]\n",
        " \n",
        "\n",
        "print(classification_report(y_val,y_predict))\n",
        "# print('Confusion Matrix:',confusion_matrix(y_val, y_predict))\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        16\n",
            "           1       1.00      0.42      0.59       294\n",
            "           2       0.00      0.00      0.00        12\n",
            "           3       1.00      0.07      0.13        29\n",
            "           4       0.88      1.00      0.94      1632\n",
            "\n",
            "    accuracy                           0.89      1983\n",
            "   macro avg       0.58      0.30      0.33      1983\n",
            "weighted avg       0.89      0.89      0.86      1983\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHpzWqTT6KbA"
      },
      "source": [
        "## Random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT0eyn9K6NqG",
        "outputId": "ab15ec94-f1d5-4f2a-e9e3-f44103b932e0"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "forest = RandomForestClassifier()\n",
        "forest = forest.fit(X_train_vectors_tfidf, y_train)\n",
        "y_pred_forest = forest.predict(X_val_vectors_tfidf)\n",
        "\n",
        "forest_accuracy = accuracy_score(y_val, y_pred_forest)\n",
        "print(model_accuracy)\n",
        "\n",
        "# We've gotten a classification rate of 95.61%. This is a pretty good accuracy score \n",
        "\n",
        "# For further evaluation you can also check the confusion matrix\n",
        "# confusion_matrix = confusion_matrix(y_val, y_pred_forest)\n",
        "# confusion_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9919314170448815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYN6ip557smU",
        "outputId": "64c0e92f-aa0e-4264-f2cd-51eeeaea6377"
      },
      "source": [
        "print(classification_report(y_val, y_pred_forest))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95        10\n",
            "           1       1.00      0.97      0.99       277\n",
            "           2       1.00      0.69      0.82        13\n",
            "           3       1.00      0.87      0.93        30\n",
            "           4       0.99      1.00      1.00      1653\n",
            "\n",
            "    accuracy                           0.99      1983\n",
            "   macro avg       1.00      0.89      0.94      1983\n",
            "weighted avg       0.99      0.99      0.99      1983\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2U2Iuf_iEfw2",
        "outputId": "8fdc44bb-a182-4105-b015-0efbdeb03b26"
      },
      "source": [
        "print(forest_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9919314170448815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhs_tma48FmV",
        "outputId": "6d882585-4fc6-4995-9960-45f6478025e9"
      },
      "source": [
        "from pprint import pprint\n",
        "# Look at parameters used by our current forest\n",
        "print('Parameters currently in use:\\n')\n",
        "pprint(forest.get_params())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters currently in use:\n",
            "\n",
            "{'bootstrap': True,\n",
            " 'ccp_alpha': 0.0,\n",
            " 'class_weight': None,\n",
            " 'criterion': 'gini',\n",
            " 'max_depth': None,\n",
            " 'max_features': 'auto',\n",
            " 'max_leaf_nodes': None,\n",
            " 'max_samples': None,\n",
            " 'min_impurity_decrease': 0.0,\n",
            " 'min_impurity_split': None,\n",
            " 'min_samples_leaf': 1,\n",
            " 'min_samples_split': 2,\n",
            " 'min_weight_fraction_leaf': 0.0,\n",
            " 'n_estimators': 100,\n",
            " 'n_jobs': None,\n",
            " 'oob_score': False,\n",
            " 'random_state': None,\n",
            " 'verbose': 0,\n",
            " 'warm_start': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFWLNnH_8Fce",
        "outputId": "95d62c2b-35dc-4a2c-ae98-e9243ae4d185"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "pprint(random_grid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'bootstrap': [True, False],\n",
            " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
            " 'max_features': ['auto', 'sqrt'],\n",
            " 'min_samples_leaf': [1, 2, 4],\n",
            " 'min_samples_split': [2, 5, 10],\n",
            " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGUYwV1D8FRB"
      },
      "source": [
        "# # Use the random grid to search for best hyperparameters\n",
        "# # First create the base model to tune\n",
        "# rf = RandomForestClassifier()\n",
        "# # Random search of parameters, using 3 fold cross validation, \n",
        "# # search across 100 different combinations, and use all available cores\n",
        "# rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# # Fit the random search model\n",
        "# rf_random.fit(X_train_vectors_tfidf, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbZieJP-8FFe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmGYvoy-8Ez7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9bjN1W2wOI0"
      },
      "source": [
        "### Support Vector Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdLLn3UawT2I"
      },
      "source": [
        "#### Linear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INOor_80hBrX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c13d975b-1bd0-4ea1-b841-e740edfcb6fb"
      },
      "source": [
        "# Import Suport Vector Classifier module from svm library. We'll use SVC to model our data\n",
        "from sklearn.svm import SVC,LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn.metrics import  accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paDSNYLxpifz"
      },
      "source": [
        "# counter = Counter(y_train)\n",
        "# print('Before',counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKBCNe61piKU"
      },
      "source": [
        "# smt = SMOTETomek(random_state=139)\n",
        "# X_train_vectors_tfidf_smtom,y_train_smtom = smt.fit_resample(X_train_vectors_tfidf, y_train)\n",
        "# counter = Counter(y_train_smtom)\n",
        "# print(\"After\",counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQSXcDDMiTFH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed07d3a4-3b34-4193-fa6d-542e336335b0"
      },
      "source": [
        "# Fit the model\n",
        "svm = SVC(kernel= 'linear', class_weight = 'balanced', C = 1.0, random_state = 10)\n",
        "svm.fit(X_train_vectors_tfidf, y_train)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=10, shrinking=True, tol=0.001,\n",
              "    verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9GeKqtx4SIC",
        "outputId": "da2672d3-038e-4d02-9eb2-41d1eaadbf57"
      },
      "source": [
        "pprint(svm.get_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method BaseEstimator.get_params of SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=False, random_state=10, shrinking=True, tol=0.001,\n",
            "    verbose=False)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PhbVsb8sAiH"
      },
      "source": [
        "y_pred_svm = svm.predict(X_val_vectors_tfidf)\n",
        "\n",
        "model_accuracy_1= accuracy_score(y_val, y_pred_svm)\n",
        "print(model_accuracy_1)\n",
        "\n",
        "# We've gotten a classification rate of 95.61%. This is a pretty good accuracy score \n",
        "\n",
        "# For further evaluation you can also check the confusion matrix\n",
        "confusion_matrix = confusion_matrix(y_val, y_pred_svm)\n",
        "confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzTPR7PKqxtj"
      },
      "source": [
        "# Fit the model\n",
        "svm = SVC(kernel= 'linear', class_weight = 'balanced', C = 0.01, gamma = 'auto')\n",
        "svm.fit(X_train_vectors_tfidf, y_train)\n",
        "\n",
        "y_pred_svm2 = svm.predict(X_val_vectors_tfidf)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PWEfmqyssv8",
        "outputId": "5e5526f1-39e1-46aa-d355-a7bfea746c54"
      },
      "source": [
        "# model_accuracy_2= accuracy_score(y_val, y_pred_svm2)\n",
        "# print(model_accuracy_2)\n",
        "\n",
        "# # We've gotten a classification rate of 95.61%. This is a pretty good accuracy score \n",
        "                                                                                          #zindi model accuracy = 0.7267864783911\n",
        "# # For further evaluation you can also check the confusion matrix\n",
        "# confusion_matrix = confusion_matrix(y_val, y_pred_svm2)\n",
        "# confusion_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9863842662632375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  10,    0,    0,    0,    0],\n",
              "       [   1,  323,    0,    0,    8],\n",
              "       [   0,    0,    8,    0,    0],\n",
              "       [   0,    0,    0,   43,    0],\n",
              "       [   2,    7,    5,    4, 1572]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "9sPpZQ2NzuXG",
        "outputId": "43c0fd72-20a3-4b86-ccd2-063a83ed0d87"
      },
      "source": [
        "model_accuracy_2= accuracy_score(y_val, y_pred_svm2)\n",
        "print(model_accuracy_2)\n",
        "\n",
        "# We've gotten a classification rate of 95.61%. This is a pretty good accuracy score \n",
        "\n",
        "# For further evaluation you can also check the confusion matrix\n",
        "confusion_matrix = confusion_matrix(y_val, y_pred_svm2)\n",
        "confusion_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9813414019162885\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-6a746c82cb9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# For further evaluation you can also check the confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mconfusion_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_svm2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "v1fiDN-EIouF",
        "outputId": "ac7f8fc8-d135-4e72-996b-e22c85c986c9"
      },
      "source": [
        "# Fit the model\n",
        "svm = SVC(kernel= 'linear', class_weight = 'balanced', C = 0.01, gamma = 'auto')\n",
        "svm.fit(X_train_vectors_tfidf, y_train)\n",
        "\n",
        "y_pred_svm2 = svm.predict(X_val_vectors_tfidf)\n",
        "\n",
        "model_accuracy_2= accuracy_score(y_val, y_pred_svm2)\n",
        "print(model_accuracy)\n",
        "\n",
        "# We've gotten a classification rate of 95.61%. This is a pretty good accuracy score \n",
        "\n",
        "# For further evaluation you can also check the confusion matrix\n",
        "confusion_matrix = confusion_matrix(y_val, y_pred_svm2)\n",
        "confusion_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9919314170448815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-bd4604149c8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# For further evaluation you can also check the confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mconfusion_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_svm2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KveNDx70iS7k"
      },
      "source": [
        "df_test['clean_text'] = df_test['tweet'].apply(lambda x: finalpreprocess(x)) #preprocess the data\n",
        "X_test=df_test['clean_text'] \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyx9lm7Wts_l"
      },
      "source": [
        "#text to vector\n",
        "X_vector=tfidf_vectorizer.transform(X_test) #converting X_test to vector\n",
        "y_predict_svm = svm.predict(X_vector)      #use the trained model on X_vector\n",
        "#y_prob = svm.predict_proba(X_vector)[:,1]\n",
        "#df_test['predict_prob']= y_prob\n",
        "y_predict_svm = le.inverse_transform(y_predict_svm)\n",
        "#final.to_csv('SVM.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbUVnGLbkIMw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "fa0f7669-e57b-4f2d-a3ef-3e1e1b598fc5"
      },
      "source": [
        "df_test['type']= y_predict_svm\n",
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet_ID</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_0095QL4S</td>\n",
              "      <td>because he was my boyfriend, and if I said no,...</td>\n",
              "      <td>boyfriend say would get mad hat sex force sex ...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_00DREW5O</td>\n",
              "      <td>lol no, I'm telling you it's not legal. It's l...</td>\n",
              "      <td>lol tell legal literally crime conversation ra...</td>\n",
              "      <td>Harmful_Traditional_practice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_00E9F5X9</td>\n",
              "      <td>Somalia's semi-autonomous Puntland region has ...</td>\n",
              "      <td>somalia semi autonomous puntland region take f...</td>\n",
              "      <td>Harmful_Traditional_practice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_00G9OSKZ</td>\n",
              "      <td>University of Cape Coast students being robbed...</td>\n",
              "      <td>university cape coast student rob rap armed ro...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_00HU96U6</td>\n",
              "      <td>\"Somebody came up behind him and stabbed him i...</td>\n",
              "      <td>somebody come behind stab back really long bla...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15576</th>\n",
              "      <td>ID_ZZR1D21T</td>\n",
              "      <td>A Teesside charity has filed a “super complain...</td>\n",
              "      <td>teesside charity file super complaint allege s...</td>\n",
              "      <td>Harmful_Traditional_practice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15577</th>\n",
              "      <td>ID_ZZSQF54Y</td>\n",
              "      <td>he ... forced me to have sex with him.</td>\n",
              "      <td>force sex</td>\n",
              "      <td>Harmful_Traditional_practice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15578</th>\n",
              "      <td>ID_ZZTN5126</td>\n",
              "      <td>Female student of medical university raped at ...</td>\n",
              "      <td>female student medical university rap gunpoint...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15579</th>\n",
              "      <td>ID_ZZWS0XZZ</td>\n",
              "      <td>Bokamoso Mpembe (20 months) (Kidnapped and kil...</td>\n",
              "      <td>bokamoso mpembe month kidnap kill mother ex bo...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15580</th>\n",
              "      <td>ID_ZZZE5A5Q</td>\n",
              "      <td>Confession: Never Really Over reminds me of my...</td>\n",
              "      <td>confession never really remind ex absolutely s...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15581 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Tweet_ID  ...                          type\n",
              "0      ID_0095QL4S  ...               sexual_violence\n",
              "1      ID_00DREW5O  ...  Harmful_Traditional_practice\n",
              "2      ID_00E9F5X9  ...  Harmful_Traditional_practice\n",
              "3      ID_00G9OSKZ  ...               sexual_violence\n",
              "4      ID_00HU96U6  ...               sexual_violence\n",
              "...            ...  ...                           ...\n",
              "15576  ID_ZZR1D21T  ...  Harmful_Traditional_practice\n",
              "15577  ID_ZZSQF54Y  ...  Harmful_Traditional_practice\n",
              "15578  ID_ZZTN5126  ...               sexual_violence\n",
              "15579  ID_ZZWS0XZZ  ...               sexual_violence\n",
              "15580  ID_ZZZE5A5Q  ...               sexual_violence\n",
              "\n",
              "[15581 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPUks0OC8nCn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqdsezHTmBvr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f8f2efe-387b-45fb-d845-af8a8fb653be"
      },
      "source": [
        "df_test.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15581 entries, 0 to 15580\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Tweet_ID    15581 non-null  object\n",
            " 1   tweet       15581 non-null  object\n",
            " 2   clean_text  15581 non-null  object\n",
            " 3   type        15581 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 487.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX27IdK-iSom",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "a75b25c5-e5c3-4c57-f21f-f014cbcf0d81"
      },
      "source": [
        "dff = df_test.copy()\n",
        "dff.drop([ 'tweet', 'clean_text'], axis = 1, inplace = True)\n",
        "dff.set_index('Tweet_ID', inplace=True)\n",
        "dff.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tweet_ID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ID_0095QL4S</th>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID_00DREW5O</th>\n",
              "      <td>Harmful_Traditional_practice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID_00E9F5X9</th>\n",
              "      <td>Harmful_Traditional_practice</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     type\n",
              "Tweet_ID                                 \n",
              "ID_0095QL4S               sexual_violence\n",
              "ID_00DREW5O  Harmful_Traditional_practice\n",
              "ID_00E9F5X9  Harmful_Traditional_practice"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nnkx-catmBM"
      },
      "source": [
        "\n",
        "dff.to_csv('Sup_Vec_strfd.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_18qKo05xr3y"
      },
      "source": [
        "#### Polynomial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOkmIUvZxqyz"
      },
      "source": [
        "# Fit the model\n",
        "rdf = SVC(kernel= 'rbf')\n",
        "rdf.fit(X_train_vectors_tfidf, y_train)\n",
        "\n",
        "y_pred_svm = rdf.predict(X_val_vectors_tfidf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mmnnjv91x3Cz",
        "outputId": "fb3bff31-58cd-4f04-fae7-567b3582af21"
      },
      "source": [
        "model_accuracy = accuracy_score(y_val, y_pred_svm)\n",
        "print(model_accuracy)\n",
        "\n",
        "# We've gotten a classification rate of 95.61%. This is a pretty good accuracy score \n",
        "\n",
        "# For further evaluation you can also check the confusion matrix\n",
        "print(classification_report(y_val,y_pred_svm))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9935804356132977\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.78      0.88        55\n",
            "           1       0.99      0.99      0.99      1948\n",
            "           2       0.96      0.68      0.80        66\n",
            "           3       0.97      0.97      0.97       233\n",
            "           4       1.00      1.00      1.00     10783\n",
            "\n",
            "    accuracy                           0.99     13085\n",
            "   macro avg       0.98      0.89      0.93     13085\n",
            "weighted avg       0.99      0.99      0.99     13085\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBtSKnnM4Plg"
      },
      "source": [
        "#text to vector\n",
        "X_vector=tfidf_vectorizer.transform(X_test) #converting X_test to vector\n",
        "y_predict_svm_p = svm.predict(X_vector)      #use the trained model on X_vector\n",
        "\n",
        "y_predict_svm_p = le.inverse_transform(y_predict_svm_p)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9ghxpDX4QJ-",
        "outputId": "a804a3dc-3a6a-4901-d8c6-4e5de4a8a715"
      },
      "source": [
        "df_test['type']= y_predict_svm_p\n",
        "print(df_test.head())\n",
        "final=df_test[['Tweet_ID']].reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Tweet_ID  ...             type\n",
            "0  ID_0095QL4S  ...  sexual_violence\n",
            "1  ID_00DREW5O  ...  sexual_violence\n",
            "2  ID_00E9F5X9  ...  sexual_violence\n",
            "3  ID_00G9OSKZ  ...  sexual_violence\n",
            "4  ID_00HU96U6  ...  sexual_violence\n",
            "\n",
            "[5 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyHtVVL_5YbQ"
      },
      "source": [
        "# df_test.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "0eR0CLea5c-H",
        "outputId": "614ef9a7-115e-4c71-daa4-6875e3b8c75b"
      },
      "source": [
        "dff = df_test.copy()\n",
        "dff.drop([ 'tweet', 'clean_text','target'], axis = 1, inplace = True)\n",
        "dff.set_index('Tweet_ID', inplace=True)\n",
        "dff.to_csv('Support_Vector_RBF.csv')\n",
        "dff"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tweet_ID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ID_0095QL4S</th>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID_00DREW5O</th>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID_00E9F5X9</th>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID_00G9OSKZ</th>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID_00HU96U6</th>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID_ZZR1D21T</th>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID_ZZSQF54Y</th>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID_ZZTN5126</th>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID_ZZWS0XZZ</th>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID_ZZZE5A5Q</th>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15581 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        type\n",
              "Tweet_ID                    \n",
              "ID_0095QL4S  sexual_violence\n",
              "ID_00DREW5O  sexual_violence\n",
              "ID_00E9F5X9  sexual_violence\n",
              "ID_00G9OSKZ  sexual_violence\n",
              "ID_00HU96U6  sexual_violence\n",
              "...                      ...\n",
              "ID_ZZR1D21T  sexual_violence\n",
              "ID_ZZSQF54Y  sexual_violence\n",
              "ID_ZZTN5126  sexual_violence\n",
              "ID_ZZWS0XZZ  sexual_violence\n",
              "ID_ZZZE5A5Q  sexual_violence\n",
              "\n",
              "[15581 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcF_b6QK_rPv"
      },
      "source": [
        "## Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBPgYPYqALit"
      },
      "source": [
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsvalnZzvNKF",
        "outputId": "46cfef04-14d0-4765-8fda-ed9226233439"
      },
      "source": [
        "mlp = MLPClassifier(hidden_layer_sizes = (13, 13,13), max_iter = 500,activation='relu')\n",
        "\n",
        "# fitting the data\n",
        "mlp.fit(X_train_vectors_tfidf,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(13, 13, 13), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDuhXS5xvoHB",
        "outputId": "83415e1a-c09a-48db-9a73-163b82fd6d08"
      },
      "source": [
        "pred = mlp.predict(X_val_vectors_tfidf)\n",
        "\n",
        "\n",
        "#print(accuracy_score(X_train_vectors_tfidf,y_train))\n",
        "\n",
        "print('-----------------------------------------------')\n",
        "\n",
        "print(classification_report(y_val,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.86         9\n",
            "           1       0.99      0.99      0.99       297\n",
            "           2       1.00      0.73      0.84        11\n",
            "           3       0.97      0.88      0.92        33\n",
            "           4       1.00      1.00      1.00      1633\n",
            "\n",
            "    accuracy                           0.99      1983\n",
            "   macro avg       0.94      0.92      0.92      1983\n",
            "weighted avg       0.99      0.99      0.99      1983\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hK7d_pQvnyf",
        "outputId": "d6edd4f2-de20-4eb4-d04e-7b802f3cdc2a"
      },
      "source": [
        "# Evaluating the performance of ur model\n",
        "print (confusion_matrix(y_val,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   9    0    0    0    0]\n",
            " [   1  294    0    0    2]\n",
            " [   1    0    8    0    2]\n",
            " [   0    0    0   29    4]\n",
            " [   1    2    0    1 1629]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVRAOMshwd7I"
      },
      "source": [
        "#text to vector\n",
        "X_vector=tfidf_vectorizer.transform(X_test) #converting X_test to vector\n",
        "y_predict = lr_tfidf.predict(X_vector)      #use the trained model on X_vector\n",
        "#y_prob = lr_tfidf.predict_proba(X_vector)[:,1]\n",
        "#df_test['predict_prob']= y_prob\n",
        "y_predict = le.inverse_transform(y_predict)\n",
        "df_test['type']= y_predict\n",
        "print(df_test.head())\n",
        "\n",
        ".drop([ 'tweet', 'clean_text',], axis = 1, inplace = True)\n",
        "attempt1.to_csv('Log_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpUujLWI_yC2"
      },
      "source": [
        "X = df_train['clean_text']\n",
        "y = df_train['type']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2yJ7vbPAQq3"
      },
      "source": [
        "# divide our data into 80% for the training set and 20% for the testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify = )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YGsuOlfLfl7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW8zFx0pAT7b"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f748ghDAYIt"
      },
      "source": [
        "# Adding 1 because of reserved 0 index\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "maxlen = 5000\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVWwQkuyAcGX"
      },
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('/content/glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary [word] = vector_dimensions\n",
        "glove_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz0AWGVGJNjo"
      },
      "source": [
        "embedding_matrix = zeros((vocab_size, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy2mCIYjJT4s",
        "outputId": "46b57ab9-004d-4821-f8dc-9f4424f3851e"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28136, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXKgcMS7JpML"
      },
      "source": [
        "from keras.layers import Bidirectional\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import LSTM\n",
        "# define problem properties\n",
        "# n_timesteps = 10\n",
        "# define LSTM\n",
        "model = Sequential()\n",
        "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "model.add(embedding_layer)\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM12yxNBKMWy",
        "outputId": "3e0f05d4-8e22-4ef5-d8c9-cb4f359f40b7"
      },
      "source": [
        "#Let's plot the summary of our model.\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 5000, 100)         2813600   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 5000, 256)         234496    \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 5000, 1)           257       \n",
            "=================================================================\n",
            "Total params: 3,048,353\n",
            "Trainable params: 234,753\n",
            "Non-trainable params: 2,813,600\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCunkuYfKUA1"
      },
      "source": [
        "#train the model on the training set \n",
        "#and evaluate its performance on the test set.\n",
        "history = model.fit(X_train, y_train, batch_size=128, epochs=11, verbose=1, validation_split=0.2)\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "# To check the test accuracy and loss we run the following code\n",
        "\n",
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV203taAKzoh"
      },
      "source": [
        "\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import TimeDistributed\n",
        "# define problem properties\n",
        "# n_timesteps = 10\n",
        "# define LSTM\n",
        "model = Sequential()\n",
        "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "model.add(embedding_layer)\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyqdK7bRK4a7",
        "outputId": "75344cf9-8f4d-4799-9135-90378cf42324"
      },
      "source": [
        "#Let's plot the summary of our model.\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 100, 100)          2813600   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 100, 256)          234496    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 100, 1)            257       \n",
            "=================================================================\n",
            "Total params: 3,048,353\n",
            "Trainable params: 234,753\n",
            "Non-trainable params: 2,813,600\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMP-alZVLCfS",
        "outputId": "39e844b2-c750-427a-9e2f-f53ddd77a8e7"
      },
      "source": [
        "#train the model on the training set \n",
        "#and evaluate its performance on the test set.\n",
        "history = model.fit(X_train, y_train, batch_size=128, epochs=11, verbose=1, validation_split=0.2)\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "# To check the test accuracy and loss we run the following code\n",
        "\n",
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/11\n",
            "199/199 [==============================] - 9s 25ms/step - loss: -28.6449 - accuracy: 0.1501 - val_loss: -38.1262 - val_accuracy: 0.1504\n",
            "Epoch 2/11\n",
            "199/199 [==============================] - 4s 19ms/step - loss: -38.2164 - accuracy: 0.1492 - val_loss: -38.1334 - val_accuracy: 0.1504\n",
            "Epoch 3/11\n",
            "199/199 [==============================] - 4s 19ms/step - loss: -38.0226 - accuracy: 0.1540 - val_loss: -38.1358 - val_accuracy: 0.1504\n",
            "Epoch 4/11\n",
            "199/199 [==============================] - 4s 19ms/step - loss: -37.9745 - accuracy: 0.1545 - val_loss: -38.1367 - val_accuracy: 0.1504\n",
            "Epoch 5/11\n",
            "199/199 [==============================] - 4s 19ms/step - loss: -38.1240 - accuracy: 0.1520 - val_loss: -38.1371 - val_accuracy: 0.1504\n",
            "Epoch 6/11\n",
            "199/199 [==============================] - 4s 19ms/step - loss: -38.1718 - accuracy: 0.1506 - val_loss: -38.1371 - val_accuracy: 0.1504\n",
            "Epoch 7/11\n",
            "199/199 [==============================] - 4s 19ms/step - loss: -38.0372 - accuracy: 0.1539 - val_loss: -38.1375 - val_accuracy: 0.1504\n",
            "Epoch 8/11\n",
            "199/199 [==============================] - 4s 19ms/step - loss: -38.1571 - accuracy: 0.1512 - val_loss: -38.1375 - val_accuracy: 0.1504\n",
            "Epoch 9/11\n",
            "199/199 [==============================] - 4s 19ms/step - loss: -38.3103 - accuracy: 0.1488 - val_loss: -38.1375 - val_accuracy: 0.1504\n",
            "Epoch 10/11\n",
            "199/199 [==============================] - 4s 20ms/step - loss: -38.2659 - accuracy: 0.1489 - val_loss: -38.1375 - val_accuracy: 0.1504\n",
            "Epoch 11/11\n",
            "199/199 [==============================] - 4s 20ms/step - loss: -38.2362 - accuracy: 0.1490 - val_loss: -38.1375 - val_accuracy: 0.1504\n",
            "248/248 [==============================] - 2s 7ms/step - loss: -38.0942 - accuracy: 0.1498\n",
            "Test Score: -38.094234466552734\n",
            "Test Accuracy: 0.14981085062026978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8BrgI4I1_So"
      },
      "source": [
        "# Import the libraries\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "from imblearn.over_sampling import SVMSMOTE\n",
        "lr_tfidf = SVMSMOTE(random_state = 101)\n",
        "\n",
        "# Choosing a sample\n",
        "X_oversample_svm, y_oversample_svm = make_classification(n_samples=10000, n_features=2,\n",
        "                                                         n_redundant=0, n_clusters_per_class=1,\n",
        "                                                         weights=[0.99], flip_y=0, random_state=101)\n",
        "\n",
        "# Perform Logistic Regression\n",
        "X_oversample_svm, y_oversample_svm = lr_tfidf.fit_resample(X_train_vectors_tfidf, y_train)\n",
        "classifier_svm = LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
        "classifier_svm.fit(X_oversample_svm, y_oversample_svm)\n",
        "\n",
        "#Predict y value for test dataset\n",
        "y_predict = classifier_svm.predict(X_val_vectors_tfidf)\n",
        "y_prob = classifier_svm.predict_proba(X_val_vectors_tfidf)[:,1]\n",
        " \n",
        "\n",
        " \n",
        "\n",
        "#print(classification_report(y_test, classifier_svm.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbyAumsK5U_F",
        "outputId": "89732ce4-fe0b-498f-d36d-db317b2d1add"
      },
      "source": [
        "\n",
        "print(classification_report(y_val, y_predict))\n",
        "print('Confusion Matrix:', confusion_matrix(y_val, y_predict))\n",
        "accuracy_score(y_val, y_predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00       284\n",
            "           2       0.67      1.00      0.80         4\n",
            "           3       1.00      1.00      1.00        28\n",
            "           4       1.00      1.00      1.00      1657\n",
            "\n",
            "    accuracy                           1.00      1983\n",
            "   macro avg       0.93      1.00      0.96      1983\n",
            "weighted avg       1.00      1.00      1.00      1983\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9984871406959153"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBve8Vk76Hx7"
      },
      "source": [
        "#text to vector\n",
        "X_vector=tfidf_vectorizer.transform(X_test) #converting X_test to vector\n",
        "y_predict_ps = classifier_svm.predict(X_vector)      #use the trained model on X_vector\n",
        "\n",
        "\n",
        "y_predict_ps = le.inverse_transform(y_predict_ps)\n",
        "\n",
        "df_test['type']= y_predict_ps\n",
        "dff = df_test.copy()\n",
        "dff.drop([ 'tweet', 'clean_text'], axis = 1, inplace = True)\n",
        "dff.set_index('Tweet_ID', inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "SpkWaBXW6vzL",
        "outputId": "541ca7da-82b5-4664-93b8-8929e6cbf176"
      },
      "source": [
        "df_test['type']= y_predict_ps\n",
        "dff.to_csv('Sup_Vector_PS2.csv')\n",
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet_ID</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>clean_text2</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_0095QL4S</td>\n",
              "      <td>because he was my boyfriend, and if I said no,...</td>\n",
              "      <td>boyfriend say would get mad hat sex force sex ...</td>\n",
              "      <td>(boyfriend, say, would, get, mad, hat, sex, fo...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_00DREW5O</td>\n",
              "      <td>lol no, I'm telling you it's not legal. It's l...</td>\n",
              "      <td>lol tell legal literally crime conversation ra...</td>\n",
              "      <td>(lol, tell, legal, literally, crime, conversat...</td>\n",
              "      <td>Harmful_Traditional_practice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_00E9F5X9</td>\n",
              "      <td>Somalia's semi-autonomous Puntland region has ...</td>\n",
              "      <td>somalia semi autonomous puntland region take f...</td>\n",
              "      <td>(somalia, semi, autonomous, puntland, region, ...</td>\n",
              "      <td>Harmful_Traditional_practice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_00G9OSKZ</td>\n",
              "      <td>University of Cape Coast students being robbed...</td>\n",
              "      <td>university cape coast student rob rap armed ro...</td>\n",
              "      <td>(university, cape, coast, student, rob, rap, a...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_00HU96U6</td>\n",
              "      <td>\"Somebody came up behind him and stabbed him i...</td>\n",
              "      <td>somebody come behind stab back really long bla...</td>\n",
              "      <td>(somebody, come, behind, stab, back, really, l...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15576</th>\n",
              "      <td>ID_ZZR1D21T</td>\n",
              "      <td>A Teesside charity has filed a “super complain...</td>\n",
              "      <td>teesside charity file super complaint allege s...</td>\n",
              "      <td>(teesside, charity, file, super, complaint, al...</td>\n",
              "      <td>Harmful_Traditional_practice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15577</th>\n",
              "      <td>ID_ZZSQF54Y</td>\n",
              "      <td>he ... forced me to have sex with him.</td>\n",
              "      <td>force sex</td>\n",
              "      <td>(force, sex)</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15578</th>\n",
              "      <td>ID_ZZTN5126</td>\n",
              "      <td>Female student of medical university raped at ...</td>\n",
              "      <td>female student medical university rap gunpoint...</td>\n",
              "      <td>(female, student, medical, university, rap, gu...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15579</th>\n",
              "      <td>ID_ZZWS0XZZ</td>\n",
              "      <td>Bokamoso Mpembe (20 months) (Kidnapped and kil...</td>\n",
              "      <td>bokamoso mpembe month kidnap kill mother ex bo...</td>\n",
              "      <td>(bokamoso, mpembe, month, kidnap, kill, mother...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15580</th>\n",
              "      <td>ID_ZZZE5A5Q</td>\n",
              "      <td>Confession: Never Really Over reminds me of my...</td>\n",
              "      <td>confession never really remind ex absolutely s...</td>\n",
              "      <td>(confession, never, really, remind, ex, absolu...</td>\n",
              "      <td>sexual_violence</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15581 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Tweet_ID  ...                          type\n",
              "0      ID_0095QL4S  ...               sexual_violence\n",
              "1      ID_00DREW5O  ...  Harmful_Traditional_practice\n",
              "2      ID_00E9F5X9  ...  Harmful_Traditional_practice\n",
              "3      ID_00G9OSKZ  ...               sexual_violence\n",
              "4      ID_00HU96U6  ...               sexual_violence\n",
              "...            ...  ...                           ...\n",
              "15576  ID_ZZR1D21T  ...  Harmful_Traditional_practice\n",
              "15577  ID_ZZSQF54Y  ...               sexual_violence\n",
              "15578  ID_ZZTN5126  ...               sexual_violence\n",
              "15579  ID_ZZWS0XZZ  ...               sexual_violence\n",
              "15580  ID_ZZZE5A5Q  ...               sexual_violence\n",
              "\n",
              "[15581 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SoGmVEW7CYU",
        "outputId": "53dbd4f7-7ca3-478c-87a1-e7e8680e82a0"
      },
      "source": [
        "df_test.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15581 entries, 0 to 15580\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Tweet_ID     15581 non-null  object\n",
            " 1   tweet        15581 non-null  object\n",
            " 2   clean_text   15581 non-null  object\n",
            " 3   clean_text2  15581 non-null  object\n",
            " 4   type         15581 non-null  object\n",
            "dtypes: object(5)\n",
            "memory usage: 608.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjT251cX7MHm"
      },
      "source": [
        "dff = df_test.copy()\n",
        "dff.drop([ 'tweet', 'clean_text'], axis = 1, inplace = True)\n",
        "dff.set_index('Tweet_ID', inplace=True)\n",
        "dff.to_csv('Sup_Vector_PS2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}